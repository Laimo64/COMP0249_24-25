{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRs0hlaVeQJ4SAHtWL8e3p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laimo64/COMP0249_24-25/blob/main/AI_small_pelvis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSKnMNNVms4L",
        "outputId": "7bf89133-0d87-4cc2-b62d-5dc1098917ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Retrieving folder 1YglgePc5HR7xwJsJ4JtxZwCxS_3w4BG1 1PA001\n",
            "Processing file 14NBV6rs0GBG153iHd7XEqYg0oTKqUJLT ct.nii.gz\n",
            "Processing file 1PLBoY1bmNQsijtF5sy1xy9CHekEdjRw0 mask.nii.gz\n",
            "Processing file 1TEC7hyly_wefXVEMkLu6O5KGvktqoHwl mr.nii.gz\n",
            "Retrieving folder 1G7EXDcDfwwyHtwuvLekjGBsfY7HMX0Vw 1PA004\n",
            "Processing file 1Kg0rpar2VH96dqIdTPw-xZ40MdeihDWh ct.nii.gz\n",
            "Processing file 1TOh8uqcwE-2JDSGoupPCpPE_VDIkFaS6 mask.nii.gz\n",
            "Processing file 1x1ZklUzMMR6bsSUhMcVvZ5mZKLMNKN4m mr.nii.gz\n",
            "Retrieving folder 1dtZxQG_73GK2E0b12bsW3Kl-1pGNIx3F 1PA005\n",
            "Processing file 1_Rs9AI_Kcxt1oTuY6RTSOSSpMjwbU0gA ct.nii.gz\n",
            "Processing file 1vxbkohAz2M-A0EWiNA6-kNb_xlpPdu48 mask.nii.gz\n",
            "Processing file 1ndEp6swdkzjVH7IkexwWn-HFp2ubd5Gm mr.nii.gz\n",
            "Retrieving folder 1ylCONRohODlpknK20m6pkNp7aVjVL8s7 1PA009\n",
            "Processing file 1PmIxMGp8Cxcy8hfDH84JfPtZJV0VPbp5 ct.nii.gz\n",
            "Processing file 1yMO7J9DSMBnDsZuNG3xbF8KEhbJdgSYl mask.nii.gz\n",
            "Processing file 1prLf0ASYhXG-FOu1iEtUnFOokn1V55Rs mr.nii.gz\n",
            "Retrieving folder 1G1jJ-UwfplovccaKTN864mcyn7PF3If4 1PA010\n",
            "Processing file 1jHiDn0sYgM2qFtGiKdLf0cy19UAklCKV ct.nii.gz\n",
            "Processing file 1-IeqIgeWVmmxA-l8EnHP6l6OfIEaxjv- mask.nii.gz\n",
            "Processing file 1q0au5PzQDt5JeiU3ksACU6i2vmL15ZeD mr.nii.gz\n",
            "Retrieving folder 19PkHhS2kHt08Q5Z_ko_HdQIMvSJ4opHT 1PA011\n",
            "Processing file 1bKaVlQeTBCS-h-Q6keoORC0C7QuBiFL2 ct.nii.gz\n",
            "Processing file 14Mu96odUFOOcWbTNLocbBFaXSheqEld_ mask.nii.gz\n",
            "Processing file 1BMFgPT6pmt5tcuk1gzzyMSVoxUmM_O5g mr.nii.gz\n",
            "Retrieving folder 1IVm1O5v3ooL9bUNyKPEsBkbpdHmHY3eA 1PA012\n",
            "Processing file 1lU5TeS5EWI0PoXotf3ENzrJZpgrebO0t ct.nii.gz\n",
            "Processing file 1fOupyrH2WEgukMmn8tleqkKMtsAkg_ki mask.nii.gz\n",
            "Processing file 1O-XcGzQ4i_tJlux6INASEYOWMOJeBIWx mr.nii.gz\n",
            "Retrieving folder 1Un4IwJsO7lHhzyarLZ06huFhcV-ij_w6 1PA014\n",
            "Processing file 18jzOJWognjJgmtx0_ockBZGMc32CYhuD ct.nii.gz\n",
            "Processing file 1OIIzaK9a7uECd8iq_g7qLC9hyqKdPTd8 mask.nii.gz\n",
            "Processing file 1vyX8gHtcJkTgsuGsS-rp_1vI__VFN2qr mr.nii.gz\n",
            "Retrieving folder 1e-rkoD7geTiPlExfF8pptr-9EKdzLxXO 1PA018\n",
            "Processing file 1KGIr4pS7tgDozE9CztCu_9cs4u0XVUbn ct.nii.gz\n",
            "Processing file 1Rn0bijWYzHnpER76oNiQQ04fo-IE-2zn mask.nii.gz\n",
            "Processing file 15-HOJiJX170eWrozWD1Pb3BlPaLuxoZr mr.nii.gz\n",
            "Retrieving folder 1e1HahbL1VbeXxqAKlwzPvg1qqK44L7Oh 1PA019\n",
            "Processing file 1yqw_3uMHrqL3xut9iQw7psg0cE963TPS ct.nii.gz\n",
            "Processing file 14_v_NW-MR4q-7RsJHWz7tCGrWKm1IfEB mask.nii.gz\n",
            "Processing file 1Cl4rQMee3EWa9JjMI4gdfPcu8RV7n-Pp mr.nii.gz\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=14NBV6rs0GBG153iHd7XEqYg0oTKqUJLT\n",
            "From (redirected): https://drive.google.com/uc?id=14NBV6rs0GBG153iHd7XEqYg0oTKqUJLT&confirm=t&uuid=9a693dbc-cd05-4c90-9e8d-c1ed500a5906\n",
            "To: /content/pelvis_smalllll/1PA001/ct.nii.gz\n",
            "100% 32.5M/32.5M [00:00<00:00, 45.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PLBoY1bmNQsijtF5sy1xy9CHekEdjRw0\n",
            "To: /content/pelvis_smalllll/1PA001/mask.nii.gz\n",
            "100% 190k/190k [00:00<00:00, 105MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1TEC7hyly_wefXVEMkLu6O5KGvktqoHwl\n",
            "From (redirected): https://drive.google.com/uc?id=1TEC7hyly_wefXVEMkLu6O5KGvktqoHwl&confirm=t&uuid=8b057fe1-b743-4186-a9b1-c1519c9be0d9\n",
            "To: /content/pelvis_smalllll/1PA001/mr.nii.gz\n",
            "100% 79.8M/79.8M [00:00<00:00, 80.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Kg0rpar2VH96dqIdTPw-xZ40MdeihDWh\n",
            "To: /content/pelvis_smalllll/1PA004/ct.nii.gz\n",
            "100% 21.9M/21.9M [00:00<00:00, 83.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TOh8uqcwE-2JDSGoupPCpPE_VDIkFaS6\n",
            "To: /content/pelvis_smalllll/1PA004/mask.nii.gz\n",
            "100% 150k/150k [00:00<00:00, 67.9MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1x1ZklUzMMR6bsSUhMcVvZ5mZKLMNKN4m\n",
            "From (redirected): https://drive.google.com/uc?id=1x1ZklUzMMR6bsSUhMcVvZ5mZKLMNKN4m&confirm=t&uuid=f840b8e5-2fb0-451c-8426-99d70d4faabf\n",
            "To: /content/pelvis_smalllll/1PA004/mr.nii.gz\n",
            "100% 51.4M/51.4M [00:01<00:00, 45.6MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1_Rs9AI_Kcxt1oTuY6RTSOSSpMjwbU0gA\n",
            "From (redirected): https://drive.google.com/uc?id=1_Rs9AI_Kcxt1oTuY6RTSOSSpMjwbU0gA&confirm=t&uuid=74c5eb6f-ca3c-4d62-b986-1dceca000301\n",
            "To: /content/pelvis_smalllll/1PA005/ct.nii.gz\n",
            "100% 44.1M/44.1M [00:00<00:00, 74.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vxbkohAz2M-A0EWiNA6-kNb_xlpPdu48\n",
            "To: /content/pelvis_smalllll/1PA005/mask.nii.gz\n",
            "100% 244k/244k [00:00<00:00, 98.6MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ndEp6swdkzjVH7IkexwWn-HFp2ubd5Gm\n",
            "From (redirected): https://drive.google.com/uc?id=1ndEp6swdkzjVH7IkexwWn-HFp2ubd5Gm&confirm=t&uuid=57a6278c-c812-4027-982a-868bc8393393\n",
            "To: /content/pelvis_smalllll/1PA005/mr.nii.gz\n",
            "100% 90.6M/90.6M [00:01<00:00, 83.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PmIxMGp8Cxcy8hfDH84JfPtZJV0VPbp5\n",
            "To: /content/pelvis_smalllll/1PA009/ct.nii.gz\n",
            "100% 22.5M/22.5M [00:00<00:00, 80.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yMO7J9DSMBnDsZuNG3xbF8KEhbJdgSYl\n",
            "To: /content/pelvis_smalllll/1PA009/mask.nii.gz\n",
            "100% 141k/141k [00:00<00:00, 75.9MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1prLf0ASYhXG-FOu1iEtUnFOokn1V55Rs\n",
            "From (redirected): https://drive.google.com/uc?id=1prLf0ASYhXG-FOu1iEtUnFOokn1V55Rs&confirm=t&uuid=751ac81a-61df-4867-a202-9b86145bf8c8\n",
            "To: /content/pelvis_smalllll/1PA009/mr.nii.gz\n",
            "100% 55.0M/55.0M [00:00<00:00, 95.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jHiDn0sYgM2qFtGiKdLf0cy19UAklCKV\n",
            "To: /content/pelvis_smalllll/1PA010/ct.nii.gz\n",
            "100% 23.4M/23.4M [00:00<00:00, 86.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-IeqIgeWVmmxA-l8EnHP6l6OfIEaxjv-\n",
            "To: /content/pelvis_smalllll/1PA010/mask.nii.gz\n",
            "100% 149k/149k [00:00<00:00, 87.6MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1q0au5PzQDt5JeiU3ksACU6i2vmL15ZeD\n",
            "From (redirected): https://drive.google.com/uc?id=1q0au5PzQDt5JeiU3ksACU6i2vmL15ZeD&confirm=t&uuid=a5c5bfa7-46a6-47d7-bf77-f940652d3d48\n",
            "To: /content/pelvis_smalllll/1PA010/mr.nii.gz\n",
            "100% 56.2M/56.2M [00:00<00:00, 89.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1bKaVlQeTBCS-h-Q6keoORC0C7QuBiFL2\n",
            "From (redirected): https://drive.google.com/uc?id=1bKaVlQeTBCS-h-Q6keoORC0C7QuBiFL2&confirm=t&uuid=d4dabbd6-494f-4755-9f7f-1245ec20eb9e\n",
            "To: /content/pelvis_smalllll/1PA011/ct.nii.gz\n",
            "100% 28.6M/28.6M [00:00<00:00, 77.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14Mu96odUFOOcWbTNLocbBFaXSheqEld_\n",
            "To: /content/pelvis_smalllll/1PA011/mask.nii.gz\n",
            "100% 178k/178k [00:00<00:00, 118MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1BMFgPT6pmt5tcuk1gzzyMSVoxUmM_O5g\n",
            "From (redirected): https://drive.google.com/uc?id=1BMFgPT6pmt5tcuk1gzzyMSVoxUmM_O5g&confirm=t&uuid=8975163e-e1e2-4d4a-89a4-2c8c56a7a107\n",
            "To: /content/pelvis_smalllll/1PA011/mr.nii.gz\n",
            "100% 71.0M/71.0M [00:02<00:00, 32.8MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1lU5TeS5EWI0PoXotf3ENzrJZpgrebO0t\n",
            "From (redirected): https://drive.google.com/uc?id=1lU5TeS5EWI0PoXotf3ENzrJZpgrebO0t&confirm=t&uuid=1612fd64-eeeb-4a71-996f-914e45e7f72e\n",
            "To: /content/pelvis_smalllll/1PA012/ct.nii.gz\n",
            "100% 31.6M/31.6M [00:00<00:00, 87.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fOupyrH2WEgukMmn8tleqkKMtsAkg_ki\n",
            "To: /content/pelvis_smalllll/1PA012/mask.nii.gz\n",
            "100% 187k/187k [00:00<00:00, 109MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1O-XcGzQ4i_tJlux6INASEYOWMOJeBIWx\n",
            "From (redirected): https://drive.google.com/uc?id=1O-XcGzQ4i_tJlux6INASEYOWMOJeBIWx&confirm=t&uuid=df320d2e-15e8-42ef-8696-2eb622cbe7b2\n",
            "To: /content/pelvis_smalllll/1PA012/mr.nii.gz\n",
            "100% 70.4M/70.4M [00:00<00:00, 125MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=18jzOJWognjJgmtx0_ockBZGMc32CYhuD\n",
            "From (redirected): https://drive.google.com/uc?id=18jzOJWognjJgmtx0_ockBZGMc32CYhuD&confirm=t&uuid=cb9538aa-370a-470d-82fb-a7dac799f6d4\n",
            "To: /content/pelvis_smalllll/1PA014/ct.nii.gz\n",
            "100% 37.2M/37.2M [00:00<00:00, 68.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OIIzaK9a7uECd8iq_g7qLC9hyqKdPTd8\n",
            "To: /content/pelvis_smalllll/1PA014/mask.nii.gz\n",
            "100% 268k/268k [00:00<00:00, 71.8MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1vyX8gHtcJkTgsuGsS-rp_1vI__VFN2qr\n",
            "From (redirected): https://drive.google.com/uc?id=1vyX8gHtcJkTgsuGsS-rp_1vI__VFN2qr&confirm=t&uuid=12de84b3-6605-48c3-980d-b940a07db6f0\n",
            "To: /content/pelvis_smalllll/1PA014/mr.nii.gz\n",
            "100% 80.4M/80.4M [00:02<00:00, 36.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KGIr4pS7tgDozE9CztCu_9cs4u0XVUbn\n",
            "To: /content/pelvis_smalllll/1PA018/ct.nii.gz\n",
            "100% 20.2M/20.2M [00:00<00:00, 67.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Rn0bijWYzHnpER76oNiQQ04fo-IE-2zn\n",
            "To: /content/pelvis_smalllll/1PA018/mask.nii.gz\n",
            "100% 136k/136k [00:00<00:00, 58.8MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=15-HOJiJX170eWrozWD1Pb3BlPaLuxoZr\n",
            "From (redirected): https://drive.google.com/uc?id=15-HOJiJX170eWrozWD1Pb3BlPaLuxoZr&confirm=t&uuid=96a3d9c6-704c-4d24-a90b-a56a7fceeeae\n",
            "To: /content/pelvis_smalllll/1PA018/mr.nii.gz\n",
            "100% 46.1M/46.1M [00:00<00:00, 71.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yqw_3uMHrqL3xut9iQw7psg0cE963TPS\n",
            "To: /content/pelvis_smalllll/1PA019/ct.nii.gz\n",
            "100% 22.8M/22.8M [00:00<00:00, 81.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14_v_NW-MR4q-7RsJHWz7tCGrWKm1IfEB\n",
            "To: /content/pelvis_smalllll/1PA019/mask.nii.gz\n",
            "100% 186k/186k [00:00<00:00, 112MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Cl4rQMee3EWa9JjMI4gdfPcu8RV7n-Pp\n",
            "From (redirected): https://drive.google.com/uc?id=1Cl4rQMee3EWa9JjMI4gdfPcu8RV7n-Pp&confirm=t&uuid=65c03550-33d8-47c1-a36c-339069cd8db0\n",
            "To: /content/pelvis_smalllll/1PA019/mr.nii.gz\n",
            "100% 52.3M/52.3M [00:00<00:00, 84.6MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!gdown --folder https://drive.google.com/drive/folders/1zERaJ8JhQsCd7-Hbx-OWImvafc47LHTc?usp=drive_link"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -q pelvis_small.zip"
      ],
      "metadata": {
        "id": "n-rNlalBzqn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "class MRCTDataset(Dataset):\n",
        "    def __init__(self, data_dir, target_size=(128, 500, 310)):\n",
        "        \"\"\"\n",
        "        初始化數據集\n",
        "        Args:\n",
        "            data_dir (str): MRI 和 CT 數據的根目錄。\n",
        "            target_size (tuple): 將 MRI 和 CT 影像調整為的固定尺寸。\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.target_size = target_size\n",
        "        self.samples = [\n",
        "            os.path.join(root)\n",
        "            for root, _, files in os.walk(data_dir)\n",
        "            if \"mr.nii.gz\" in files and \"ct.nii.gz\" in files\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        根據索引返回一組 MR 和 CT 影像。\n",
        "        Args:\n",
        "            idx (int): 數據的索引。\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: MR 和 CT 的張量形式。\n",
        "        \"\"\"\n",
        "        sample_path = self.samples[idx]\n",
        "\n",
        "        # 加載 MRI 和 CT 影像\n",
        "        mr = nib.load(os.path.join(sample_path, \"mr.nii.gz\")).get_fdata()\n",
        "        ct = nib.load(os.path.join(sample_path, \"ct.nii.gz\")).get_fdata()\n",
        "\n",
        "        # Z-score 標準化\n",
        "        mr = self._normalize(mr)\n",
        "        ct = self._normalize(ct)\n",
        "\n",
        "        # 調整或填充影像大小\n",
        "        mr = self._resize_or_pad(mr, self.target_size)\n",
        "        ct = self._resize_or_pad(ct, self.target_size)\n",
        "\n",
        "        # 轉換為 PyTorch 張量並增加通道維度\n",
        "        mr = torch.tensor(mr, dtype=torch.float32).unsqueeze(0)  # (1, D, H, W)\n",
        "        ct = torch.tensor(ct, dtype=torch.float32).unsqueeze(0)  # (1, D, H, W)\n",
        "\n",
        "        return mr, ct\n",
        "\n",
        "    def _normalize(self, image):\n",
        "        \"\"\"\n",
        "        Z-score 標準化影像數據。\n",
        "        Args:\n",
        "            image (np.ndarray): 輸入影像。\n",
        "        Returns:\n",
        "            np.ndarray: 標準化的影像。\n",
        "        \"\"\"\n",
        "        if np.std(image) != 0:\n",
        "            return (image - np.mean(image)) / np.std(image)\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "    def _resize_or_pad(self, image, desired_shape):\n",
        "        \"\"\"\n",
        "        調整影像大小或填充至固定大小。\n",
        "        Args:\n",
        "            image (np.ndarray): 輸入影像。\n",
        "            desired_shape (tuple): 目標大小。\n",
        "        Returns:\n",
        "            np.ndarray: 調整或填充後的影像。\n",
        "        \"\"\"\n",
        "        current_shape = image.shape\n",
        "        scale = [d / c for d, c in zip(desired_shape, current_shape)]\n",
        "        resized_image = zoom(image, scale, order=1)  # 調整大小\n",
        "\n",
        "        # 填充影像至目標大小\n",
        "        padded_image = np.zeros(desired_shape, dtype=resized_image.dtype)\n",
        "        pad_slices = tuple(slice(0, min(dim, resized_image.shape[i])) for i, dim in enumerate(desired_shape))\n",
        "        padded_image[pad_slices] = resized_image[:desired_shape[0], :desired_shape[1], :desired_shape[2]]\n",
        "\n",
        "        return padded_image\n"
      ],
      "metadata": {
        "id": "fzm3XNAe0TYS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "data_path = \"/content/pelvis_smalllll\"\n",
        "output_root = \"/content/split\"  # 輸出目錄\n",
        "\n",
        "# 創建輸出資料夾\n",
        "os.makedirs(output_root, exist_ok=True)\n",
        "os.makedirs(os.path.join(output_root, \"train\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_root, \"validation\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_root, \"test\"), exist_ok=True)\n",
        "\n",
        "# 獲取所有樣本資料夾名稱\n",
        "samples = [name for name in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, name))]\n",
        "\n",
        "# 按照 70:15:15 的比例分割\n",
        "train_samples, test_samples = train_test_split(samples, test_size=0.3, random_state=42)\n",
        "validation_samples, test_samples = train_test_split(test_samples, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Total samples: {len(samples)}\")\n",
        "print(f\"Train samples: {len(train_samples)}, Validation samples: {len(validation_samples)}, Test samples: {len(test_samples)}\")\n",
        "\n",
        "# 定義拷貝函數\n",
        "def move_samples(samples, output_dir):\n",
        "    for sample in samples:\n",
        "        src_path = os.path.join(data_path, sample)  # 原始路徑\n",
        "        dst_path = os.path.join(output_dir, sample)  # 目標路徑\n",
        "        if os.path.exists(dst_path):\n",
        "            print(f\"Sample {sample} already exists in {output_dir}, skipping.\")\n",
        "            continue\n",
        "        shutil.copytree(src_path, dst_path)  # 拷貝整個資料夾\n",
        "        # print(f\"Moved {sample} to {output_dir}\")\n",
        "\n",
        "# 將樣本移動到各自的資料夾\n",
        "move_samples(train_samples, os.path.join(output_root, \"train\"))\n",
        "move_samples(validation_samples, os.path.join(output_root, \"validation\"))\n",
        "move_samples(test_samples, os.path.join(output_root, \"test\"))\n",
        "\n",
        "print(\"Data split and moved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpGMTW8D04hy",
        "outputId": "9e17bd06-76d3-4248-bebc-d424c0b262ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 10\n",
            "Train samples: 7, Validation samples: 1, Test samples: 2\n",
            "Data split and moved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Swin Transformer Block (簡化版，適用於3D)\n",
        "class SwinTransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, input_size):\n",
        "        super(SwinTransformerBlock, self).__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fc = nn.Linear(dim, dim)\n",
        "        self.window_size = input_size // 4  # 分割窗口，根據3D的尺寸調整\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, d, h, w = x.shape  # 3D 輸入\n",
        "        x = x.view(b, -1, c)  # 展平為序列\n",
        "        x = self.norm(x)\n",
        "        x = self.fc(x)\n",
        "        return x.view(b, c, d, h, w)  # 還原為 3D\n",
        "\n",
        "# MSEP 網路\n",
        "class MSEP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MSEP, self).__init__()\n",
        "        # Encoder 部分\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv3d(1, 64, kernel_size=3, stride=1, padding=1),  # 使用3D卷積\n",
        "            nn.ReLU(),\n",
        "            nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1),  # 使用3D卷積\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Skip 連接部分 + RDSformer\n",
        "        self.skip = SwinTransformerBlock(128, input_size=160)\n",
        "        # Decoder 部分\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose3d(128, 64, kernel_size=3, stride=1, padding=1),  # 使用3D反卷積\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose3d(64, 1, kernel_size=3, stride=1, padding=1)  # 使用3D反卷積\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.encoder(x)\n",
        "        skip = self.skip(enc)  # 加入 skip connection\n",
        "        dec = self.decoder(skip)\n",
        "        return dec\n",
        "\n",
        "# Initialize model\n",
        "model = MSEP()\n",
        "\n",
        "# Test the model with dummy data (e.g., [Batch Size, Channel, Depth, Height, Width])\n",
        "dummy_input = torch.randn(1, 1, 128, 128, 128)  # 假設數據大小是 [1, 1, 128, 128, 128]\n",
        "output = model(dummy_input)\n",
        "\n",
        "print(\"Output shape:\", output.shape)  # 應該返回符合預期的 3D 輸出\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTueEgHw1BOD",
        "outputId": "eda0d869-ae02-4569-fbe8-e9c1943c140f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 1, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=True, delta=0.00005, path=\"checkpoint.pt\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): 容忍驗證損失未改善的次數 (default: 5)\n",
        "            verbose (bool): 是否打印相關資訊 (default: False)\n",
        "            delta (float): 最小改善幅度，只有超過此值才算改善 (default: 0)\n",
        "            path (str): 模型權重保存路徑 (default: \"checkpoint.pt\")\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float(\"inf\")\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        # 計算當前得分（驗證損失的負值，因為越小越好）\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        \"\"\"保存當前模型權重\"\"\"\n",
        "        if self.verbose:\n",
        "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\")\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "def visualize_results(input_image, target_image, predicted_image, epoch, idx, batch_idx=0):\n",
        "    \"\"\"\n",
        "    視覺化輸入影像、目標影像與預測影像\n",
        "    \"\"\"\n",
        "    input_image = input_image[batch_idx, 0].cpu().detach().numpy()  # [depth, height, width]\n",
        "    target_image = target_image[batch_idx, 0].cpu().detach().numpy()\n",
        "    predicted_image = predicted_image[batch_idx, 0].cpu().detach().numpy()\n",
        "\n",
        "    num_slices = input_image.shape[0]  # 影像深度（切片數量）\n",
        "\n",
        "    fig, axes = plt.subplots(num_slices, 3, figsize=(10, num_slices * 3))\n",
        "    axes = np.atleast_2d(axes)  # 確保 axes 是 2D\n",
        "\n",
        "    for i in range(num_slices):\n",
        "        axes[i, 0].imshow(input_image[i], cmap=\"gray\")\n",
        "        axes[i, 0].set_title(f\"Input MR - Slice {i}\")\n",
        "        axes[i, 0].axis(\"off\")\n",
        "\n",
        "        axes[i, 1].imshow(target_image[i], cmap=\"gray\")\n",
        "        axes[i, 1].set_title(f\"Target CT - Slice {i}\")\n",
        "        axes[i, 1].axis(\"off\")\n",
        "\n",
        "        axes[i, 2].imshow(predicted_image[i], cmap=\"gray\")\n",
        "        axes[i, 2].set_title(f\"Predicted CT - Slice {i}\")\n",
        "        axes[i, 2].axis(\"off\")\n",
        "\n",
        "    plt.suptitle(f\"Epoch {epoch}, Batch {idx}, Patient {batch_idx}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "bxlTyOhJ1rmm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpoint"
      ],
      "metadata": {
        "id": "MK8wF0TZHTw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def save_checkpoint(epoch, val_loss, optimizer, model, path):\n",
        "    filename = path\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'val_loss': val_loss,\n",
        "    }, filename)\n",
        "    print(f\"Checkpoint saved at {filename}\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, path, device='cuda'):\n",
        "    if not os.path.exists(path):\n",
        "          print(f\"Checkpoint file '{path}' does not exist. Starting from scratch.\")\n",
        "          return model, optimizer, 0, float('inf')  # 返回初始值\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    val_loss = checkpoint['val_loss']\n",
        "    print(f\"Checkpoint loaded from {path}, starting from epoch {epoch+1}\" )\n",
        "    return model, optimizer, epoch, val_loss\n"
      ],
      "metadata": {
        "id": "HlMhl97XGXUJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 優化器與損失函數\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)  # 學習率調整\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "# 訓練參數\n",
        "epochs = 1\n",
        "best_loss = float(\"inf\")\n",
        "\n",
        "train_path = \"/content/split/train\"\n",
        "valid_path = \"/content/split/validation\"\n",
        "test_path = \"/content/split/test\"\n",
        "\n",
        "train_dataset = MRCTDataset(train_path)\n",
        "valid_dataset = MRCTDataset(valid_path)\n",
        "test_dataset = MRCTDataset(test_path)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
        "\n",
        "for mr, ct in train_loader:\n",
        "    print(f\"MR shape: {mr.shape}, CT shape: {ct.shape}\")\n",
        "    break\n",
        "\n",
        "# early_stopping = EarlyStopping(patience=5, verbose=True, path=\"best_model.pt\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # 訓練階段\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "    for mr, ct in progress_bar:\n",
        "        mr, ct = mr.to(device), ct.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(mr)\n",
        "        loss = criterion(output, ct)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "    # if epoch % 5 == 0:  # 每 5 個 epoch 可視化一次\n",
        "    #     visualize_results(mr, ct, output, epoch, idx=1)\n",
        "    # visualize_results(mr, ct, output, epoch, idx=1)\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Avg Train Loss: {avg_train_loss}\")\n",
        "\n",
        "    # 驗證階段\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for mr, ct in val_loader:\n",
        "            mr, ct = mr.to(device), ct.to(device)\n",
        "            output = model(mr)\n",
        "            loss = criterion(output, ct)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Avg Validation Loss: {avg_val_loss}\")\n",
        "    # save_checkpoint(epoch, avg_val_loss, g_optimizer, model, path=\"generator_checkpoint.pth\")\n",
        "\n",
        "\n",
        "\n",
        "visualize_results(mr, ct, output, epoch, idx=1, batch_idx=0)\n"
      ],
      "metadata": {
        "id": "nAAJLHr91ugS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "db104986-cb52-4ef6-c2f9-d8ec7167078f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch._dynamo' has no attribute 'config' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-13ab3c4ac7c3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 優化器與損失函數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 學習率調整\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCapturedTraceback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_traceback_short\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbytecode_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_dead_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_pointless_jumps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m from .bytecode_transformation import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   3216\u001b[0m         \u001b[0;34m\"torch.distributed._composable.replicate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3217\u001b[0m     }\n\u001b[0;32m-> 3218\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_fsdp_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3219\u001b[0m         \u001b[0mLEGACY_MOD_INLINELIST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch.distributed._composable.fsdp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'config' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "\n",
        "# 讀取 NIfTI 檔案\n",
        "nii_file = nib.load(\"/content/pelvis_smalllll/1PA001/ct.nii.gz\")\n",
        "\n",
        "# 獲取影像數據的形狀\n",
        "image_shape = nii_file.shape\n",
        "\n",
        "print(\"影像大小:\", image_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn0ZHuCeIgYZ",
        "outputId": "f1f29a7f-0684-46a3-80ad-f3dbbcf1ea85"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "影像大小: (565, 338, 146)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "\n",
        "# 讀取 NIfTI 檔案\n",
        "nii_file = nib.load(\"/content/pelvis_smalllll/1PA014/ct.nii.gz\")\n",
        "\n",
        "# 獲取影像數據的形狀\n",
        "image_shape = nii_file.shape\n",
        "\n",
        "print(\"影像大小:\", image_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqEGXzpLIj1O",
        "outputId": "c5a4c60f-11cc-4be7-9f42-672e012593af"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "影像大小: (568, 392, 147)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Df1_rb2IqYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}